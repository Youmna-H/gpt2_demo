{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "[GPT-2](https://openai.com/blog/better-language-models/#sample8) is a generative language model. The model is trained on 40GB of web text. It works by predicting the next word given the previous words in a text, and therefore, could be used to generate a continuation of a given text.\n",
    "\n",
    "An example of a text generated by GPT-2:\n",
    "\n",
    "prompt: I think Leonardo Dicaprio's performance was\n",
    "\n",
    "Generated text: excellent,\" said director Roman Polanski, who directed all of Polanski's movies with Polanski in the past. \"I just felt the same way after the movie as I did after 'Django Unchained,' which is that he makes you feel a certain way, which isn't that great, but he knows where to go with it. If I could say a bit more about it, I'd say it's a good little family film. And then there's the\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Package installation\n",
    "These commands should be executed once at the beginning in order to install the packages required to run the model. You should get the right command for installing PyTorch from https://pytorch.org/get-started/locally/#start-locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package installation\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import packages\n",
    "Run these comands in the beginning in order to import the different packages in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2TokenizerFast, GPT2LMHeadModel, set_seed\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model parameters\n",
    "You can set different parameters for the GPT-2 model as follows:\n",
    "1. 'model_name': GPT-2 comes in different sizes based on the number of training parameters:\n",
    "    - 'gpt2': 117M parameters\n",
    "    - 'gpt2-medium': 345M parameters\n",
    "    - 'gpt2-large': 774M parameters\n",
    "    - 'gpt2-xl': 1558M parameters\n",
    "\n",
    "    Note that the larger the model, the longer it takes to load and use for generation.\n",
    "\n",
    "2. 'num_samples': the number of sample responses to generate.\n",
    "\n",
    "3. 'max_length': the maximum number of words to be generated in a response.\n",
    "\n",
    "4. 'sampling': The model generates the response word by word, conditioned on the input text and the sequence of words generated so far in the respose. There are different sampling strategies such as:\n",
    "    - 'top-p' (nucleas sampling)\n",
    "    - 'top-k' \n",
    "    - 'temperature'\n",
    "    \n",
    "    You can also combine different sampling approaches, but for simplicity, we will skip that. This is a nice blog post on sampling: https://huggingface.co/blog/how-to-generate\n",
    "\n",
    "5. After choosing the 'sampling' strategy, you can set the corresponding value: 'top-p', 'top-k' or 'temperature', where 0 $\\leqslant$ top-p $\\leqslant$ 1, top-k $\\geqslant$ 0, and 0 $\\leqslant$ temperature $\\leqslant$ 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model_name': 'gpt2-medium',\n",
    "    'num_samples': 3,\n",
    "    'max_length': 100,\n",
    "    'sampling': 'top-p',\n",
    "    'top-p': 0.92,\n",
    "    'top-k': 40,\n",
    "    'temperature': 0.7,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Loading the model\n",
    "The following command loads the model into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "set_seed(42)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(params['model_name'])\n",
    "model = GPT2LMHeadModel.from_pretrained(params['model_name'], pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reading the input\n",
    "We can input the text that GPT-2 will respond to either by command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think Leonardo Dicaprio's performance was\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"I think Leonardo Dicaprio's performance was\"]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generation with interactive mode\n",
    "prompts = []\n",
    "prompt = input()\n",
    "prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or from a text file (input.txt) where each line contains a different prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating from a text file\n",
    "prompts = []\n",
    "with open('input.txt') as f:\n",
    "    for line in f:\n",
    "        prompt = line.strip()\n",
    "        if prompt == '':\n",
    "            continue\n",
    "        prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generating the output\n",
    "By running this code you can generate the GPT-2 responses corresponding to the provided prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation itself\n",
    "output = {}\n",
    "for text in prompts:\n",
    "\tinput_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "\tmax_length = len(text.split()) + params['max_length']\n",
    "\tresponses = []\n",
    "\tif params['sampling'] == 'top-k':\n",
    "\t\tresponses = model.generate(input_ids, max_length = max_length, do_sample=True, \n",
    "            top_k=params['top-k'], num_return_sequences=params['num_samples'])\n",
    "\telif params['sampling'] == 'temperature':\n",
    "\t\tresponses = model.generate(input_ids, max_length = max_length, do_sample=True, \n",
    "            temperature=params['temperature'], num_return_sequences=params['num_samples'])\n",
    "    #default is nuclear (top-p)\n",
    "\telse:\n",
    "\t\tresponses = model.generate(input_ids, max_length = max_length, do_sample=True, \n",
    "            top_p=params['top-p'], num_return_sequences=params['num_samples'])\n",
    "# \tresponses = model.generate(input_ids, max_length=max_length)\n",
    "\tresponses = responses[:, input_ids.shape[-1]:]\n",
    "\toutput[text] = []\n",
    "\tfor i, r in enumerate(responses):\n",
    "\t\tresponse = tokenizer.decode(r, skip_special_tokens=True)#.strip().split('\\n')[0]\n",
    "\t\toutput[text].append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the output here by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: Does Brexit have a positive impact on the British economy?\n",
      "\n",
      "==================================Sample 1==================================\n",
      "There are many factors that have to be considered when comparing the impact of Brexit to its predecessors such as the impact on GDP and trade. However, the short-term impacts seem to be positive - the economy is expected to grow by 0.6 per cent during the next two years.\n",
      "\n",
      "In terms of long-term GDP and employment, the Bank of England has warned Brexit could add 2.8 million jobs over the next three years. These are expected to be largely in the\n",
      "\n",
      "==================================Sample 2==================================\n",
      "It depends entirely on how you define \"positive impact\". There are many ways to measure this – for example, GDP in the UK has fallen by 0.2% in 2017, according to Eurostat (it's now down 0.2%). GDP growth in the US, on the other hand, has increased by almost 0.3%, according to the US Bureau of Economic Analysis (BEA).\n",
      "\n",
      "Of course, the US economy does not respond to the UK's departure.\n",
      "\n",
      "==================================Sample 3==================================\n",
      "The recent Brexit vote suggests that we have the opportunity to have a positive impact on the economy – and Brexit will give us the opportunity. We believe that this will happen not in one-off small steps but through a steady process of growth and growth with time.\n",
      "\n",
      "How will economic growth be achieved if the UK leaves the EU?\n",
      "\n",
      "One possible outcome is that the UK would stay within the single market while remaining outside it. This would allow the UK to continue to receive the\n",
      "\n",
      "********************************************************************************************************************\n",
      "\n",
      "prompt: In order to overcome depression, you need to\n",
      "\n",
      "==================================Sample 1==================================\n",
      "be fully present with everything happening around you, and if possible, even when you're not feeling the effects of the disorder. You may need to seek help or therapy when you find yourself feeling overwhelmed or overwhelmed by the amount of things to do or get done. Also consider finding some other people you can talk to, even if you can't do it alone. There may be situations you can turn to, if you're having trouble concentrating and are looking for help or support.\n",
      "\n",
      "You can\n",
      "\n",
      "==================================Sample 2==================================\n",
      "make positive changes in your life. So you must make it a priority in your everyday life. So make it a priority to live healthy. Make it a priority to exercise and to eat a healthy diet. That's why the world's biggest mental health organizations say that most people with depression are suffering from it. People are suffering from it because they are living lives that don't fit with their values. It's not about what's healthy. It's about what's right.\n",
      "\n",
      "In order\n",
      "\n",
      "==================================Sample 3==================================\n",
      "overcome your fear. As it happens, it's actually your fear that has caused this. However, you don't want to have anything to do with it because you're afraid of your fear. You need to think about yourself as being different and change that fear into something that actually motivates you to accomplish things. For example, I have a friend who once said to me, \"Well, you know how you always do the same thing all the time? Well, maybe we need to think\n",
      "\n",
      "********************************************************************************************************************\n",
      "\n",
      "prompt: Do you bellieve in love at the first sight?\n",
      "\n",
      "==================================Sample 1==================================\n",
      "- The answer is no! When you begin to love someone, you'll need time to find a reason. When you find the reason, you'll start to love them. You might wonder if your reason is genuine. Your reason may not be enough. You might wonder if there is an alternative to finding the solution. You might wonder if there is anything you can do about it. You might even wonder if you deserve to be loved. You'll want to know, however, why you\n",
      "\n",
      "==================================Sample 2==================================\n",
      "And for whom do you seek the best? I tell you that your love will take you to Heaven\" (Lk 17:37).\n",
      "\n",
      "When you come out to love someone, do not think of yourself as in a perfect situation. The truth is that you will never know whether or not someone else loved you back when you first met them. And love can be more difficult than you realize and can seem lonely, or difficult. Do not let the fear of missing out on someone\n",
      "\n",
      "==================================Sample 3==================================\n",
      "It does not matter whether you have love for each other in the sense that you know them to be, or merely for what their character is, because they are the same and love is the same. Love is a result from the union of the qualities of both of which both of you are capable, and from which you, as members of the same person, are capable of expressing with pleasure or delight, even when neither of you are present at the union. Therefore, just as the union\n",
      "\n",
      "********************************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in output:\n",
    "    print('prompt: ' + k + '\\n')\n",
    "    for i, r in enumerate(output[k]):\n",
    "        print('==================================Sample ' + str(i+1) + '==================================')\n",
    "        print(r.strip() + '\\n')\n",
    "    print('********************************************************************************************************************')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or save it to a file by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open('gpt2_output.txt', 'w')\n",
    "for k in output:\n",
    "    fw.write('prompt: ' + k + '\\n\\n')\n",
    "    for i, r in enumerate(output[k]):\n",
    "        fw.write('==================================Sample ' + str(i+1) + '==================================\\n')\n",
    "        fw.write(r.strip() + '\\n')\n",
    "    fw.write('********************************************************************************************************************\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
